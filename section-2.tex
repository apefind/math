
\newpage
\section{Nonlinear Optimization}
\subsection{Minimization without Constraints}
\bigskip


\begin{lemma}[Gradient Inequality]\label{thm:lemma_gradient_inequality}
    Let \(M \subseteq \mathbb{R}^n \) be a convex set and \(f \in C^1(M)\). Then \(f\) is convex if and only if
    \[
        f(x) \ge f(y) + \gradient {f(y)}^T (x - y)
    \]
    for all \(x, y \in M \).
\end{lemma}

\begin{proof}
    Let f be convex and \(x, y \in M\). For \( 0 \le \lambda \le 1 \) follows
    \[
        f(\lambda x + (1 - \lambda) y) \le \lambda f(x) + (1 - \lambda)f(y) =  \lambda f(x) - \lambda f(y) + f(y)
    \]
    and
    \[
        f(x) - f(y) \ge \frac{f(\lambda x + (1 - \lambda) y) - f(y)}{\lambda}
        = \frac{f(y + \lambda (x - y)) - f(y)}{\lambda}
    \]
    For \( d = x - y \)\ and \( \lambda \to 0 \) the term on the right converges to the direction derivative of \( f \)
    in \( d \)
    \[
        \frac{\partial f}{\partial d}(y) = \gradient{f(y)}^T d = \gradient{f(y)}^T (x - y)
    \]

    Now let \( x, y \in M \) and  \( 0 \le \lambda \le 1 \). For \( z = \lambda x + (1 - \lambda) y \in M \) 
    it follows that
    \[
        \begin{split}
            \lambda f(x) & \ge \lambda f(z) + \lambda \gradient {f(z)}^T (x - z) \\
            (1 - \lambda) f(y) & \ge (1 - \lambda) f(z) + (1 - \lambda) \gradient {f(z)}^T (y - z)
        \end{split}
    \]
    Adding the two inequalities gives
    \[
        \begin{split}
            \lambda f(x) + (1 - \lambda) f(y)
            & \ge f(z) + \gradient {f(z)}^T(\lambda x - \lambda z + (1- \lambda) y - (1-\lambda)z) \\
            & = f(z) + \gradient {f(z)}^T(\lambda x + (1- \lambda) y - z) \\
            & = f(z)
        \end{split}
    \]
\end{proof}
\bigskip


\begin{exercise}[Facility Locations]
    The facilities are located at:
    \[
        (3, 0), (0, -3), (1, 4)
    \]
\end{exercise}

\begin{proof}
    Let
    \[
        \begin{split}
            f(x)    & = {(x - 3)}^2 + y^2 + x^2 + {(y + 3)}^2 + {(x - 1)}^2 + {(y - 4)}^2 \\
            & = x^2 - 6x + 9 + y^2 + x^2 + y^2 + 6y + 9 + x^2 - 2x + 1 + y^2 -8y + 16 \\
            & = 3x^2 + 3y^2 - 8x - 2y + 35
        \end{split}
    \]
    Then
    \[
        \gradient f(x, y) = (6x - 8, 6y - 2) \text{ and } \gradient^2 f(x, y) =
        \begin{pmatrix}
            6 & 0 \\
            0 & 6 \\
        \end{pmatrix} > 0
    \]
    Hence \( (4 / 3, 1 / 3) \) is the gobal minimum.
\end{proof}
\bigskip


\exercise[Convex Functions]
The sum of convex functions is convex.

\proof{}
Let \( x, y \in M \). Since \( \alpha_i  > 0 \) it is
\[
    \begin{split}
        f(\lambda x + (1 - \lambda) y)
        & = \sum_{i=1}^m \alpha_i f_i(\lambda x + (1 - \lambda) y) \\
        & \le \sum_{i=1}^m \alpha_i \lambda f_i(x) + \sum_{i=1}^m \alpha_i (1 - \lambda) f_i(y)
        =  \lambda f(x) + (1 - \lambda) f(y)
    \end{split}
\]
Let \( f(x) = x^2 \). Then \( -f \) is not convex, e.g. \( x = 1, y = -1 \) and \( \lambda = 0.5 \).
\bigskip


\exercise[Solution of Quadratic Inequality]
Let
\[
    f(x) = x^{T}Ax + b^{T}x + c
\]
\proof{}
The product rule gives
\[
    \gradient {f(x)} = x^{T}A + Ax + b = (A^{T} + A)x + b = 2Ax + b
\]
Thus \( \hessian {f(x)} = 2A > 0 \) and \( f \) is convex. Hence the level set \( \Gamma_{-c} \) is convex.
Since the intersection of convex sets is convex \( \Gamma_{-c} \cap \{ x \in \Rn: g^{T}x + h = 0 \} \) 
is convex, too.
\bigskip


\exercise[Line Search on Compact Convex Sets]
Let \( S \subset \mathbb{R}^n \) be compact and convex. Furthermore let \( f \in C^1(S) \) be convex,
\( x \in S \) and \( d \in \mathbb{R}^n \) a descent direction of \( f \) in \( x \)
with \( \gradient {f(x)}^T d < 0 \).

\proof{}
If  \( x + \lambda^* d \) is an optimal solution then \( \gradient {f(x + \lambda^* d)}^T d = 0 \)
according to Theorem~\ref{thm:fonc}.
Let \( \gradient {f(x + \lambda^* d)}^T d = 0 \). Then Lemma~\ref{thm:lemma_gradient_inequality} gives
\[
    f(x + \lambda d) \ge f(x + \lambda^* d) + (\lambda - \lambda^*) \gradient {f(x + \lambda^* d)}^T d
    = f(x + \lambda^* d)
\]
and \( x + \lambda^* d \) is an optimal solution.
\bigskip


\begin{exercise}[Steepest Descent]
    Let
    \[
        f(x) = \frac{1}{2} x^T{A}x + b^T x + c
    \]
    where \( A \) is symmetrical and positive definite.
\end{exercise}

\begin{proof}
    Since \( \gradient {f(x)} = Ax + b \) and \( \hessian {f(x)} = A > 0 \) it follows \( x^* = -A^{-1}b \).
    Let \( v \) be eigenvector with \( Av = \mu v \). For \( x_0 = x^* + \theta v \) it follows
    \[
        \gradient {f(x_0)} = Ax^* + \mu \theta v + b = \mu \theta v
    \]
    and for \(\lambda \ge 0 \)
    \[
        \argmin \{ f(x_0 - \lambda \gradient f(x_0) \} =
            \argmin \{ f(x^* + \theta v - \lambda \mu \theta v)\} = \mu^{-1}
    \]
    Thus
    \[
        x_1 = x_0 - \mu^{-1} \gradient f(x_0) = x^* + \theta v - \mu^{-1} \mu \theta v = x^*
    \]
    and \( \gradient {f(x_1)} = 0 \). Hence the algorithm stops after the first iteration.
    Now let
    \[
        x_0 = x^* + \sum_{i=0}^m \theta_i v_i
    \]
    for orthogonal eigenvectors with \( Av_i = \mu_i\) and \( m \le n \). Then
    \[
        \gradient {f(x_0)} = Ax^* + \sum_{i=0}^m \mu_i \theta_i v_i + b = \sum_{i=0}^m \mu_i \theta_i v_i
    \]
    and
    \[
        x_1 = x_0 - \lambda \sum_{i=0}^m \mu_i \theta_i v_i
        = x^* + \sum_{i=0}^m \theta_i v_i - \lambda \sum_{i=0}^m \mu_i \theta_i v_i
        = x^* + \sum_{i=0}^m (1 - \lambda \mu_i) \theta_i v_i
    \]
    Since \( x^* \) is the minimum it follows \( \gradient {f(x_1)} = 0 \) iff \( \lambda = \mu^{-1} \) 
    for all \( 0 \le i \le m \).
\end{proof}
\bigskip



\subsection{One Dimensional Minimization and Direct Search}
\bigskip


\begin{definition}[Unimodal Function]\label{def:unimodal_fnc}
    A function \( f : [a,b] \to \R \) is called unimodal if there exists a \( \xi \in [a,b] \), so that
    \( f \) is strictly decreasing in \( [a, \xi] \) and strictly increasing in \( [\xi, b] \).
\end{definition}
\bigskip

In fact \( \xi \) is the unique minimum of \( f \) in \( [a, b] \). According to the definition,
for \( a \le x < y \le b \) follows
\[
    f(x) > f(y) \text{ for } x, y \in [a, \xi) \text{ and } f(x) < f(y) \text{ for }  x, y \in (\xi, b]   % chktex 9
\]
Thus
\[
    \xi \in [a, y] \text{ if } f(x) < f(y) \text{ and } \xi \in [x, b] \text{ if } f(x) \ge f(y)
\]

Consider now a symmetrical partioning of the interval \( [0, 1] \) where two consecutive partionings hold
the same ratio respectively:
\[
    \sigma = 1 - \tau \text{ and } \frac{1}{\tau} = \frac{\tau}{\sigma}
\]
Then \( 1 - \tau = \tau^2 \) and solving the quadratic equation \( \tau^2 + \tau = 1 \) yields
\[
    \tau = \frac{\sqrt{5} - 1}{2} \approx 0.61803
\]
\bigskip

\begin{figure}[H]
    \centering
    \plotgoldensection{}
    \caption{Golden Section}\label{fig:golden_section}
\end{figure}
\bigskip

Let now \( [a_0, b_0] = [a, b] \) and define
\[
    [a_{k + 1}, b_{k + 1}] =
    \begin{cases}
        [a_k, y_k] & \text{ if } f(x_k) < f(y_k)   \\
        [x_k, b_k] & \text{ if } f(x_k) \ge f(y_k)
    \end{cases}
\]
where
\[
    \begin{split}
        x_k & = b_k - \tau (b_k - a_k) \\
        y_k & = a_k + \tau (b_k - a_k)
    \end{split}
\]
It follows that \( [a_k, b_k] \supset [a_{k + 1}, b_{k + 1}] \) is a decreasing series of intervals with
\[
    (b_{k + 1} - a_{k + 1}) =  \tau(b_k - a_k)
\]
where the interval converges to \( \xi \). This leads to the following algorithm:
\bigskip

\begin{algorithm}[Golden Section Search]\label{algo:golden_section_search}
\end{algorithm}
\inputminted[fontsize=\small, framesep=0.35cm, frame=lines, python3=true]{python}{python/golden_section.py}
\bigskip

\begin{exercise}[Surprising Convergence]
    Example for \( f \in C^2(\mathbb{R}) \) with a sequence of strict local minima converging to a strict local maximum.
\end{exercise}
\bigskip



\subsection{Methods of Steepest Descent}
\bigskip


\begin{definition}
    Let \( f \in C^1(\Rn) \) and \( x_0 \in \Rn \) an arbitraty starting point.
    \begin{enumerate}
        \item For sequences \( \lambda_k > 0 \) and unit vectors \( s_k \in \Rn \) define
              \[
                  x_{k + 1} = x_k + \lambda_k s_k
              \]
        \item Assume there exists \( 0 < \alpha \le 1 \) so that
              \[
                  - \gradient f(x_k) s_k \ge \alpha \|\gradient f(x_k)\|
              \]
        \item Furthermore assume that for some \( 0 < \beta \le \gamma < 1 \) the following inequalities hold
              \[
                  f(x_{k + 1}) \le f(x_k) + \lambda_k \beta \gradient f(x_k) s_k
              \]
              \[
                  \gradient f(x_{k + 1}) s_k \ge \gamma \gradient f(x_k) s_k
              \]
    \end{enumerate}
    Then \( \lambda_k \) and  \( s_k \) are called \emph{step lengths} and \emph{search directions} respectively
    and \( x_k \) is called a \emph{sequence of descent} for \( f \).
\end{definition}
\bigskip


\begin{remarks}
    The inequalities above serve different purposes
    \begin{enumerate}
        \item  It is
              \[
                  - \gradient f(x_k) s_k = \cos\varphi \|\gradient f(x_k)\| \|s_k\| =
                  \cos\varphi \|\gradient f(x_k)\| \ge \alpha \|\gradient f(x_k)\|
              \]
              Hence the angle between the direction of the steepest descent and the search direction is
              strictly smaller then \( \ang{90} \) degrees.
        \item  Since \( \gradient f(x_k) s_k \le 0 \) it follows
              \[
                  f(x_{k + 1}) \le f(x_k) + \beta \lambda_k \gradient f(x_k) s_k \le f(x_k)
              \]
              and \( f(x_k) \) is monotonically decreasing.
        \item Furthermore
              \[
                  \gradient f(x_{k + 1}) s_k = \gradient f(x_k + \lambda_k s_k) s_k
                  \ge \gamma \gradient f(x_k) s_k
              \]
              Hence the step length cannot be chosen too small due to the continuity of the dervative.
    \end{enumerate}
\end{remarks}
\bigskip


\begin{theorem}[Steepest Descent Method]\label{thm:steepest_descent}
    Let \( f \in C^2(\Rn) \) and \( x_k \) a sequence of descent for \( f \).
    Then every accumulation point of \( x_k \) is a stationary point of \( f \).
\end{theorem}

\begin{proof}
\end{proof}
