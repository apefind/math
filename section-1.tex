
\newpage
\section{Introduction}

\begin{theorem}[Fermat Stationary Point]\label{thm:fermat_stationary_point}
Let \( \Omega \subseteq \R \) be open and \( f \in C^1(\Omega) \). If \( x^* \in \Omega \) is local extremum 
then \( f^\prime(x^*) = 0 \).
\end{theorem}

\begin{proof}
Assume \( x^* \) is the minimum of \( f \) in \( \Omega \) and let \( f^\prime(x^*) > 0 \). 
Since \( f \in C^1(\Omega) \) there exist \( \eps, \delta > 0 \), so that for \( |h| \le \eps \)
\[
    \frac{f(x^* + h) - f(x^*)}{h} > \delta
\]
Pick a negative \( h \in [-\eps, 0) \). Then 
\[
     f(x^* + h) < f(x^*) +  \delta h < f(x^*) 
\]
and \( x^* \) cannot be the minimum. Analog for maximum with a positive \( h \), then apply to \( -f \).
\end{proof}
\bigskip


\begin{theorem}[Rolle]\label{thm:rolle}
Let \( f \in C[a,b] \) with \( f(a) = f(b) \). If \( f \) is differentiable in \( (a, b) \) then 
there exists a \( \xi \in (a,b) \) with \( f^\prime(\xi) = 0 \).
\end{theorem}

\begin{proof}
Assume \( f \) is not constant. Since \( [a,b] \) is compact there exists a global minimum or maximum 
\( \xi \in (a,b) \) and Theorem~\ref{thm:fermat_stationary_point} can be applied.
\end{proof}
\bigskip


\begin{theorem}[Mean Value]\label{thm:mean_value}
Let \( f \in C[a,b] \) be differentiable in \( (a, b) \). Then there exists a \( \xi \in (a,b) \) with 
\[
    f^\prime(\xi) = \frac{f(b) - f(a)}{b - a}
\]
\end{theorem}

\begin{proof}
Apply Theorem~\ref{thm:rolle} to 
\[
    g(x) = f(x) - \frac{f(b) - f(a)}{b - a} (x -a) 
\]
\end{proof}
\bigskip

\begin{remark}\hfill
    \begin{enumerate}
        \item More generally choose any \( \varphi \in C^1[a,b] \) with \( \varphi(a) = 0 \) and 
            \( \varphi(b) = f(b) - f(a) \). Set \( g(x) = f(x) - \varphi(x) \) to see there is a \( \xi \in (a,b) \) 
            with \( f^\prime(\xi) = \varphi^\prime(\xi)\). 
        \item Another useful generalization: let \( \Omega \subseteq \Rn \) be open and \( f \in C^1(\Omega) \). For
            \( x, y \in \Omega \) define \( \varphi(t) = f(tx + (1 - t)y) \) and apply the chain rule:
            \[
                 \varphi^\prime(\xi) = \gradient f(\xi x + (1 - \xi)y)(x - y) = f(x) - f(y)
            \]
        \item The Cauhy Schwarz inequality then yields
            \[
                  \|f(x) - f(y)\| \le \|\gradient f(\xi x + (1 - \xi)y)\| \|(x - y)\|
            \]
    \end{enumerate}
\end{remark}
\bigskip


\begin{lemma}[Direction Derivative]\label{lemma:direction_derivative}
Let \( \Omega \subseteq \Rn \) be open, \( f \in C^1(\Omega) \) and \( d \in \Rn \) be a feasable direction 
at \( x \in \Omega \). Then
\[
    \frac{\partial f}{\partial d}(x) = \gradient{f(x)}^T d
\] 
\end{lemma}
\bigskip


\begin{theorem}[First Order Necessary Condition]\label{thm:fonc}
Let \( \Omega \subseteq \Rn \) be open and \( f \in C^1(\Omega) \). If \( x^* \in \Omega \) is a local minimzer then
\( \gradient f(x^*) = 0 \).
\end{theorem}

\begin{proof}
Let \( h \in \Rn \) and \( \delta > 0 \) so that \( x^* + th \in \Omega \) for all \( t \in (-\delta, \delta) \). 
Then \( 0 \) is local minimizer for \( \varphi(t) = f(x^* + th) \) and
\[
    \varphi^\prime(0) = {\gradient f(x^*)}^T h = 0
\]
Now let \( h = \gradient f(x^*) \). 
\end{proof}
\bigskip
