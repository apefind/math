
\newpage
\section{Calculus}

\subsection{Differentation and Integration}


\begin{lemma}[Simple Calculations]\hfill
    \begin{enumerate}
        \item For \( 1 = x x^{-1} \) the product rule yields \( 0 = x^{-1} + x(x^{-1})' \). Hence
            \[
                \frac{d}{dx} x^{-1} = -\frac{1}{x^2}
            \]
        \item Similarly \( x = \sqrt{x}^2 \) and \( 1 = 2 \sqrt{x} \sqrt{x}' \) and so
            \[
                \frac{d}{dx} \sqrt{x} = \frac{1}{2\sqrt{x}}
            \]
        \item \( (1 - q) (1 + q + q^2 + \cdots + q^n) = 1 - q + q - q^2 + q^2 - q^3 + \cdots + q^{n+1} \) gives
            \[
                \sum_{k=0}^n q^k = \frac{1 - q^{n+1}}{1 - q} \text{ and }
                \sum_{k=m}^n q^k = \frac{q^m - q^{n+1}}{1 - q}
            \]
        \item It is 
            \[
                \frac{d}{dx} x^n = nx^{n - 1}
            \]
			since the product rule yields
            \[
                \frac{d}{dx} x^n = \frac{d}{dx} xx^{n -1} = x^{n -1} + \frac{d}{dx} x^{n - 1} = 
					x^{n -1} + (n - 1)x^{n - 1}  = nx^{n - 1}
            \]
			via induction.
    \end{enumerate}
\end{lemma}
\bigskip


\begin{lemma}[Sinus and Cosinus]\hfill
    \begin{enumerate}
        \item Sinus and Cosinus power series
			\[
				\begin{split}
					\cos(x) &= \sum_{k=0}^\infty \frac{(-1)^k}{2k!} x^{2k} \\
					\sin(x) &= \sum_{k=0}^\infty \frac{(-1)^k}{(2k + 1)!} x^{2k + 1}
				\end{split}
			\]
        \item Symmetry
			\[
				\begin{split}
					\cos(-x) &= \sum_{k=0}^\infty \frac{(-1)^k}{2k!} {(-x)}^{2k} = \cos(x) \\
					\sin(x) &= \sum_{k=0}^\infty \frac{(-1)^k}{(2k + 1)!} {(-x)}^{2k + 1} = -\sin(x)
				\end{split}
			\]
        \item Derivatives
			\[
				\begin{align}
					\cos'(x) &= \sum_{k=1}^\infty \frac{(-1)^k}{(2k - 1)!} x^{2k - 1} 
						= \sum_{k=0}^\infty \frac{(-1)^{k + 1}}{(2k + 1)!} x^{2k + 1} = -\sin(x) \\
					\sin'(x) &= \sum_{k=0}^\infty \frac{(-1)^k}{2k!} {x}^{2k} = \cos(x)
				\end{align}
			\]
    \end{enumerate}
\end{lemma}
\bigskip


\begin{theorem}[Fermat Stationary Point]\label{thm:fermat_stationary_point}
Let \( \Omega \subseteq \R \) be open and \( f \in C^1(\Omega) \). If \( x^* \in \Omega \) is local extremum 
then \( f^\prime(x^*) = 0 \).
\end{theorem}

\begin{proof}
Assume \( x^* \) is the minimum of \( f \) in \( \Omega \) and let \( f^\prime(x^*) > 0 \). 
Since \( f \in C^1(\Omega) \) there exist \( \eps, \delta > 0 \), so that for \( |h| \le \eps \)
\[
    \frac{f(x^* + h) - f(x^*)}{h} > \delta
\]
Pick a negative \( h \in [-\eps, 0) \). Then 
\[
     f(x^* + h) < f(x^*) +  \delta h < f(x^*) 
\]
and \( x^* \) cannot be the minimum. Analog for maximum with a positive \( h \), then apply to \( -f \).
\end{proof}
\bigskip


\begin{theorem}[Rolle]\label{thm:rolle}
Let \( f \in C[a,b] \) with \( f(a) = f(b) \). If \( f \) is differentiable in \( (a, b) \) then 
there exists a \( \xi \in (a,b) \) with \( f^\prime(\xi) = 0 \).
\end{theorem}

\begin{proof}
Assume \( f \) is not constant. Since \( [a,b] \) is compact there exists either a global minimum or maximum 
\( \xi \in (a,b) \) and Theorem~\ref{thm:fermat_stationary_point} can be applied.
\end{proof}
\bigskip


\begin{theorem}[Mean Value]\label{thm:mean_value}
Let \( f \in C[a,b] \) be differentiable in \( (a, b) \). Then there exists a \( \xi \in (a,b) \) with 
\[
    f^\prime(\xi) = \frac{f(b) - f(a)}{b - a}
\]
\end{theorem}

\begin{proof}
Apply Theorem~\ref{thm:rolle} to 
\[
    g(x) = f(x) - \frac{f(b) - f(a)}{b - a} (x -a) 
\]
\end{proof}
\bigskip

\begin{remark}\hfill
    \begin{enumerate}
        \item More generally choose any \( \varphi \in C^1[a,b] \) with \( \varphi(a) = 0 \) and 
            \( \varphi(b) = f(b) - f(a) \). Set \( g(x) = f(x) - \varphi(x) \) to see there is a \( \xi \in (a,b) \) 
            with \( f^\prime(\xi) = \varphi^\prime(\xi)\). 
        \item Another useful generalization: let \( \Omega \subseteq \Rn \) be open and \( f \in C^1(\Omega) \). For
            \( x, y \in \Omega \) define \( \varphi(t) = f(tx + (1 - t)y) \) and apply the chain rule for differentiation
            \[
                 \varphi^\prime(\xi) = \gradient {f(\xi x + (1 - \xi)y)}^T(x - y) = f(x) - f(y)
            \]
        \item The Cauchy Schwarz inequality then yields
            \[
                  \|f(x) - f(y)\| \le \|\gradient f(\xi x + (1 - \xi)y)\| \|(x - y)\|
            \]
    \end{enumerate}
\end{remark}
\bigskip

\begin{theorem}[Differentiation Theorem]\label{thm:differentiation}
Let \( f \in C[a,b] \) and define 
\[
    F(x) = \int_a^x f(t)\,dt
\]
Then \( F \in C^1[a,b] \) with \( F^\prime(x) = f(x) \) for \( x \in [a,b] \).
\end{theorem}

\begin{proof}
Applying the Mean Value Theorem of Integration gives
\[
    F(x + h) - F(x) =  \int_x^{x + h} f(t)\,dt = f(\xi) h
\]
for some \( \xi \in (x, x + h) \).
\end{proof}
\bigskip

\begin{theorem}[Fundamental Theorem of Calculus]\label{thm:fund_calculus}
Let \( f \in C[a,b] \). Then
\[
    F(b) -F(a) = \int_a^b f(t)\,dt
\]
\end{theorem}


\subsection{Directional Derivative and Gradients}


\begin{lemma}[Directional Derivative]\label{lemma:directional_derivative}
Let \( \Omega \subseteq \Rn \) be open and \( f \in C^1(\Omega) \). Then
\[
    \frac{\partial f}{\partial d}(x) = \gradient{f(x)}^T d
\]
for any \( d \in \Rn \).
\end{lemma}

\begin{proof}
Let \( \varphi(t) = f(x + td) \). Then \( \varphi \in C^1[-\eps, \eps ] \) for some \( \eps > 0 \) 
and the chain rule yields 
\[ 
    \varphi^\prime(t) = {\gradient f(x + td)}^T d 
\]
Hence
\[
    \varphi^\prime(0) = \lim_{t \to 0} \frac{\varphi(x + td) - \varphi(0)}{t} = 
        \lim_{t \to 0} \frac{f(x + td) - f(x)}{t} = {\gradient f(x)}^T d
\]
\end{proof}
\bigskip

\begin{remark}\hfill
    \begin{enumerate}
        \item Note that by definition the directional derivative is invariant under multiplication 
            with any \( \lambda \ne 0 \).

        \item A similar proposition holds under the weaker assumption that \( d \) is a only feasable direction 
            for \( f \) in \( x \)

        \item For \( d = \gradient{f(x)}/\| \gradient{f(x)}\| \) it follows that
            \[
                \frac{\partial f}{\partial d}(x) = \|\gradient{f(x)}\| > 0
            \]
            and for any other \( d \in \Rn \) with \( \|d\| = 1 \) the Cauchy Schwarz inequality yields
            \[
                |\frac{\partial f}{\partial d}(x)| = |\gradient{f(x)}^T d| \le \|\gradient{f(x)}\| \|d\| = 
                    \|\gradient{f(x)}\|
            \]
            Hence \( \gradient{f(x)} \) is the direction of the greatest ascent and respectively, 
            \( -\gradient{f(x)} \) is the direction of the greatest descent.
    \end{enumerate}
\end{remark}
\bigskip

\begin{theorem}[First Order Necessary Condition]\label{thm:fonc}
Let \( \Omega \subseteq \Rn \) be open and \( f \in C^1(\Omega) \). If \( x^* \in \Omega \) is a local minimzer then
\( \gradient f(x^*) = 0 \).
\end{theorem}

\begin{proof}
Let \( h \in \Rn \) and \( \delta > 0 \) so that \( x^* + th \in \Omega \) for all \( t \in (-\delta, \delta) \). 
Then \( 0 \) is local minimizer for \( \varphi(t) = f(x^* + th) \) and
\[
    \varphi^\prime(0) = {\gradient f(x^*)}^T h = 0
\]
Now let \( h = \gradient f(x^*) \). 
\end{proof}
\bigskip 


\begin{theorem}[Banach Fixed-Point Theorem]\label{thm:banach_fix_point}
Let \( X \) be a Banach space and \( f \in C(X,X) \) a contraction
\[
    \|f(x) - f(y)\| \le q \|x - y\| \text{ for all } x, y \in X
\]
for some \( 0 < q < 1 \). Then there exists a unique fix point \( x^* \in X \) with 
\[
     f(x^*) = x^*
\]
Furthermore for any \( x_0 \in X \) the sequence defined by
\[
     x_{n+1} = f(x_n)
\]
converges aganist \( x^* \).
\end{theorem}

\begin{proof}
Since \( \| x_{n+1} - x_n\| =\| f(x_n) - f(x_{n-1})\| \le q\| x_n - x_{n-1}\| \) it follows, that
\[ 
    \| x_{n+1} - x_n\| \le q^n  \|x_1 - x_0\| 
\] 
Furthermore
\[ 
    \| x_n - x_m\| \le \sum_{k=m}^n q^k \|x_1 - x_0\| = \frac{q^m - q^{n+1}}{1 - q} \|x_1 - x_0\| 
\] 
and \( (x_n) \) is a Cauchy sequence. For its limit \( x^* \) we have
\[ 
   x^* = \lim_{n\to\infty} x_{n+1} = \lim_{n\to\infty} f(x_n) = f(x^*)
\] 
For any other \( y^* \in X \) with \( f(y^*) = y^* \) it follows, that
\[
    \|x^* - y^*\| = \|f(x^*) - f(y^*)\| \le q \|x^* - y^*\|
\]
and therefore \( x^* = y^*\).

\end{proof}
\bigskip

